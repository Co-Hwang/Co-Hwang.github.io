<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">

<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="RDD,">










<meta name="description" content="Spark之RDD RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合。RDD具有数据流模型的特点：自动容错、位置感知性调度和可伸缩性。RDD允许用户在执行多个查询时显式地将工作集缓存在内存中，后续的查询能够重用工作集，这极大地提升了查询速度。">
<meta name="keywords" content="RDD">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark学习之路（二）Spark之RDD">
<meta property="og:url" content="http://yoursite.com/2019/07/25/Spark学习之路（二）Spark之RDD/index.html">
<meta property="og:site_name" content="这個人好蠢、">
<meta property="og:description" content="Spark之RDD RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合。RDD具有数据流模型的特点：自动容错、位置感知性调度和可伸缩性。RDD允许用户在执行多个查询时显式地将工作集缓存在内存中，后续的查询能够重用工作集，这极大地提升了查询速度。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79ly1g5cgirdxbij319q0gsq7i.jpg">
<meta property="og:image" content="http://ww3.sinaimg.cn/large/006tNc79ly1g5cgjgurnuj319g0sugpf.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79ly1g5cgoksaq7j318y03yq3w.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79ly1g5cgpwikfhj319606wt9s.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/006tNc79ly1g5chb99yksj31ac0skwk4.jpg">
<meta property="og:image" content="http://ww4.sinaimg.cn/large/006tNc79ly1g5chdemdk2j30da09gwer.jpg">
<meta property="og:image" content="http://ww4.sinaimg.cn/large/006tNc79ly1g5chggq4anj30xa0u00xq.jpg">
<meta property="og:image" content="http://ww4.sinaimg.cn/large/006tNc79ly1g5chhg53a1j310j0u0div.jpg">
<meta property="og:image" content="http://ww3.sinaimg.cn/large/006tNc79ly1g5chkiow63j30pm0gy0uu.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79ly1g5chlnynazj30ya0ladiw.jpg">
<meta property="og:updated_time" content="2019-07-26T12:27:07.289Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark学习之路（二）Spark之RDD">
<meta name="twitter:description" content="Spark之RDD RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合。RDD具有数据流模型的特点：自动容错、位置感知性调度和可伸缩性。RDD允许用户在执行多个查询时显式地将工作集缓存在内存中，后续的查询能够重用工作集，这极大地提升了查询速度。">
<meta name="twitter:image" content="http://ww2.sinaimg.cn/large/006tNc79ly1g5cgirdxbij319q0gsq7i.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/07/25/Spark学习之路（二）Spark之RDD/">





  <title>Spark学习之路（二）Spark之RDD | 这個人好蠢、</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <a href="https://github.com/Co-Hwang"><img style="position: absolute; top: 0; left: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_left_red_aa0000.png" alt="Fork me on GitHub"></a>


    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">这個人好蠢、</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">哪懂坚持 | 全靠死撑</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>




<script>
  
  window.onload = function(){
    var path = 'https://Co-Hwang.github.io'; //
    var localhostItem = String(window.location).split(path)[1];
    var LiNode = document.querySelectorAll('#menu > li > a')
    
    for(var i = 0; i< LiNode.length;i++){
      var item = String(LiNode[i].href).split(path)[1];
      if(item == localhostItem && item != undefined){
        LiNode[i].setAttribute('style','border-bottom:1px solid black');
      }
    }
  };

</script>
 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/25/Spark学习之路（二）Spark之RDD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="想当校长的老王">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="这個人好蠢、">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Spark学习之路（二）Spark之RDD</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-25T22:27:38+08:00">
                2019-07-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3.8k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  14 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><font size="5"><strong>Spark之RDD</strong></font></p>
<p>RDD（Resilient Distributed Dataset）叫做<font color="#dd0000"><strong>弹性分布式数据集</strong>，<strong>是Spark中最基本的数据抽象</strong></font>，它代表一个不可变、可分区、里面的元素可并行计算的集合。RDD具有数据流模型的特点：自动容错、位置感知性调度和可伸缩性。RDD允许用户在执行多个查询时显式地将工作集缓存在内存中，后续的查询能够重用工作集，这极大地提升了查询速度。</p>
<a id="more"></a>

<p>本文参考：<a href="https://www.cnblogs.com/qingyunzong/p/8899715.html" target="_blank" rel="noopener">扎心了,老铁</a></p>
<h2 id="一、RDD概述"><a href="#一、RDD概述" class="headerlink" title="一、RDD概述"></a>一、RDD概述</h2><p><strong>A、RDD的属性</strong></p>
<p>（1）一组分片（Partition），即数据集的基本组成单位。对于RDD来说，每个分片都会被一个计算任务处理，并决定并行计算的粒度。用户可以在创建RDD时指定RDD的分片个数，如果没有指定，那么就会采用默认值。默认值就是程序所分配到的CPU Core的数目。</p>
<p>（2）一个计算每个分区的函数。Spark中RDD的计算是以分片为单位的，每个RDD都会实现compute函数以达到这个目的。compute函数会对迭代器进行复合，不需要保存每次计算的结果。</p>
<p>（3）RDD之间的依赖关系。RDD的每次转换都会生成一个新的RDD，所以RDD之间就会形成类似于流水线一样的前后依赖关系。在部分分区数据丢失时，Spark可以通过这个依赖关系重新计算丢失的分区数据，而不是对RDD的所有分区进行重新计算。</p>
<p>（4）一个Partitioner，即RDD的分片函数。当前Spark中实现了两种类型的分片函数，一个是基于哈希的HashPartitioner，另外一个是基于范围的RangePartitioner。只有对于于key-value的RDD，才会有Partitioner，非key-value的RDD的Parititioner的值是None。Partitioner函数不但决定了RDD本身的分片数量，也决定了parent RDD Shuffle输出时的分片数量。</p>
<p>（5）一个列表，存储存取每个Partition的优先位置（preferred location）。对于一个HDFS文件来说，这个列表保存的就是每个Partition所在的块的位置。按照“移动数据不如移动计算”的理念，Spark在进行任务调度的时候，会尽可能地将计算任务分配到其所要处理数据块的存储位置。</p>
<p><strong>B、WordCount粗图解RDD</strong></p>
<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g5cgirdxbij319q0gsq7i.jpg" alt="WordCount-RDD"></p>
<p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g5cgjgurnuj319g0sugpf.jpg" alt="hello-RDD"></p>
<h2 id="二、RDD创建方式"><a href="#二、RDD创建方式" class="headerlink" title="二、RDD创建方式"></a>二、RDD创建方式</h2><p><strong>A、通过读取文件生成的</strong></p>
<p>由外部存储系统的数据集创建，包括本地的文件系统，还有所有Hadoop支持的数据集，比如HDFS、Cassandra、HBase等</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> file = sc.textFile(<span class="string">"/spark/hello.txt"</span>)</span><br></pre></td></tr></table></figure>

<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g5cgoksaq7j318y03yq3w.jpg" alt="Tmp1"></p>
<p><strong>B、通过并行化的方式创建RDD</strong></p>
<p>由一个已经存在的Scala集合创建。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> array = <span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">array: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(array)</span><br><span class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">27</span>] at parallelize at &lt;console&gt;:<span class="number">26</span></span><br><span class="line"></span><br><span class="line">scala&gt;</span><br></pre></td></tr></table></figure>

<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g5cgpwikfhj319606wt9s.jpg" alt="Tmp2"></p>
<p><strong>C、其他方式</strong></p>
<p>读取数据库等等其他的操作。也可以生成RDD。</p>
<p>RDD可以通过其他的RDD转换而来的。</p>
<h2 id="三、RDD编程API"><a href="#三、RDD编程API" class="headerlink" title="三、RDD编程API"></a>三、RDD编程API</h2><p>Spark支持两个类型（算子）操作：Transformation和Action</p>
<p><strong>A、Transformation</strong></p>
<p>主要做的是就是将一个已有的RDD生成另外一个RDD。Transformation具有<strong>lazy特性(延迟加载)</strong>。Transformation算子的代码不会真正被执行。只有当我们的程序里面遇到一个action算子的时候，代码才会真正的被执行。这种设计让Spark更加有效率地运行。</p>
<p><font color="#dd0000"><strong>常用的Transformation：</strong></font></p>
<table>
<thead>
<tr>
<th align="center"><strong>转换</strong></th>
<th align="center"><strong>含义</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>map</strong>(func)</td>
<td align="center">返回一个新的RDD，该RDD由每一个输入元素经过func函数转换后组成</td>
</tr>
<tr>
<td align="center"><strong>filter</strong>(func)</td>
<td align="center">返回一个新的RDD，该RDD由经过func函数计算后返回值为true的输入元素组成</td>
</tr>
<tr>
<td align="center"><strong>flatMap</strong>(func)</td>
<td align="center">类似于map，但是每一个输入元素可以被映射为0或多个输出元素（所以func应该返回一个序列，而不是单一元素）</td>
</tr>
<tr>
<td align="center"><strong>mapPartitions</strong>(func)</td>
<td align="center">类似于map，但独立地在RDD的每一个分片上运行，因此在类型为T的RDD上运行时，func的函数类型必须是Iterator[T] =&gt; Iterator[U]</td>
</tr>
<tr>
<td align="center"><strong>mapPartitionsWithIndex</strong>(func)</td>
<td align="center">类似于mapPartitions，但func带有一个整数参数表示分片的索引值，因此在类型为T的RDD上运行时，func的函数类型必须是(Int, Interator[T]) =&gt; Iterator[U]</td>
</tr>
<tr>
<td align="center"><strong>sample</strong>(withReplacement, fraction, seed)</td>
<td align="center">根据fraction指定的比例对数据进行采样，可以选择是否使用随机数进行替换，seed用于指定随机数生成器种子</td>
</tr>
<tr>
<td align="center"><strong>union</strong>(otherDataset)</td>
<td align="center">对源RDD和参数RDD求并集后返回一个新的RDD</td>
</tr>
<tr>
<td align="center"><strong>intersection</strong>(otherDataset)</td>
<td align="center">对源RDD和参数RDD求交集后返回一个新的RDD</td>
</tr>
<tr>
<td align="center"><strong>distinct</strong>([numTasks]))</td>
<td align="center">对源RDD进行去重后返回一个新的RDD</td>
</tr>
<tr>
<td align="center"><strong>groupByKey</strong>([numTasks])</td>
<td align="center">在一个(K,V)的RDD上调用，返回一个(K, Iterator[V])的RDD</td>
</tr>
<tr>
<td align="center"><strong>reduceByKey</strong>(func, [numTasks])</td>
<td align="center">在一个(K,V)的RDD上调用，返回一个(K,V)的RDD，使用指定的reduce函数，将相同key的值聚合到一起，与groupByKey类似，reduce任务的个数可以通过第二个可选的参数来设置</td>
</tr>
<tr>
<td align="center"><strong>aggregateByKey</strong>(zeroValue)(seqOp, combOp, [numTasks])</td>
<td align="center">先按分区聚合 再总的聚合   每次要跟初始值交流 例如：aggregateByKey(0)(<em>+</em>,<em>+</em>) 对k/y的RDD进行操作</td>
</tr>
<tr>
<td align="center"><strong>sortByKey</strong>([ascending], [numTasks])</td>
<td align="center">在一个(K,V)的RDD上调用，K必须实现Ordered接口，返回一个按照key进行排序的(K,V)的RDD</td>
</tr>
<tr>
<td align="center"><strong>sortBy</strong>(func,[ascending], [numTasks])</td>
<td align="center">与sortByKey类似，但是更灵活 第一个参数是根据什么排序  第二个是怎么排序 false倒序   第三个排序后分区数  默认与原RDD一样</td>
</tr>
<tr>
<td align="center"><strong>join</strong>(otherDataset, [numTasks])</td>
<td align="center">在类型为(K,V)和(K,W)的RDD上调用，返回一个相同key对应的所有元素对在一起的(K,(V,W))的RDD  相当于内连接（求交集）</td>
</tr>
<tr>
<td align="center"><strong>cogroup</strong>(otherDataset, [numTasks])</td>
<td align="center">在类型为(K,V)和(K,W)的RDD上调用，返回一个(K,(Iterable<v>,Iterable<w>))类型的RDD</w></v></td>
</tr>
<tr>
<td align="center"><strong>cartesian</strong>(otherDataset)</td>
<td align="center">两个RDD的笛卡尔积  的成很多个K/V</td>
</tr>
<tr>
<td align="center"><strong>pipe</strong>(command, [envVars])</td>
<td align="center">调用外部程序</td>
</tr>
<tr>
<td align="center"><strong>coalesce</strong>(numPartitions<strong>)</strong></td>
<td align="center">重新分区 第一个参数是要分多少区，第二个参数是否shuffle 默认false  少分区变多分区 true   多分区变少分区 false</td>
</tr>
<tr>
<td align="center"><strong>repartition</strong>(numPartitions)</td>
<td align="center">重新分区 必须shuffle  参数是要分多少区  少变多</td>
</tr>
<tr>
<td align="center"><strong>repartitionAndSortWithinPartitions</strong>(partitioner)</td>
<td align="center">重新分区+排序  比先分区再排序效率高  对K/V的RDD进行操作</td>
</tr>
<tr>
<td align="center"><strong>foldByKey</strong>(zeroValue)(seqOp)</td>
<td align="center">该函数用于K/V做折叠，合并处理 ，与aggregate类似   第一个括号的参数应用于每个V值  第二括号函数是聚合例如：<em>+</em></td>
</tr>
<tr>
<td align="center"><strong>combineByKey</strong></td>
<td align="center">合并相同的key的值 rdd1.combineByKey(x =&gt; x, (a: Int, b: Int) =&gt; a + b, (m: Int, n: Int) =&gt; m + n)</td>
</tr>
<tr>
<td align="center"><strong>partitionBy**</strong>（partitioner）**</td>
<td align="center">对RDD进行分区  partitioner是分区器 例如new HashPartition(2</td>
</tr>
<tr>
<td align="center"><strong>cache / persist</strong></td>
<td align="center">RDD缓存，可以避免重复计算从而减少时间，区别：cache内部调用了persist算子，cache默认就一个缓存级别MEMORY-ONLY ，而persist则可以选择缓存级别</td>
</tr>
<tr>
<td align="center"><strong>Subtract（rdd）</strong></td>
<td align="center">返回前rdd元素不在后rdd的rdd</td>
</tr>
<tr>
<td align="center"><strong>leftOuterJoin</strong></td>
<td align="center">leftOuterJoin类似于SQL中的左外关联left outer join，返回结果以前面的RDD为主，关联不上的记录为空。只能用于两个RDD之间的关联，如果要多个RDD关联，多关联几次即可。</td>
</tr>
<tr>
<td align="center"><strong>rightOuterJoin</strong></td>
<td align="center">rightOuterJoin类似于SQL中的有外关联right outer join，返回结果以参数中的RDD为主，关联不上的记录为空。只能用于两个RDD之间的关联，如果要多个RDD关联，多关联几次即可</td>
</tr>
<tr>
<td align="center"><strong>subtractByKey</strong></td>
<td align="center">substractByKey和基本转换操作中的subtract类似只不过这里是针对K的，返回在主RDD中出现，并且不在otherRDD中出现的元素</td>
</tr>
</tbody></table>
<p><strong>B、Action</strong></p>
<p>触发代码的运行，我们一段spark代码里面至少需要有一个action操作。</p>
<p><font color="#dd0000"><strong>常用的Action：</strong></font></p>
<table>
<thead>
<tr>
<th align="center"><strong>动作</strong></th>
<th align="center"><strong>含义</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>reduce</strong>(<em>func</em>)</td>
<td align="center">通过func函数聚集RDD中的所有元素，这个功能必须是课交换且可并联的</td>
</tr>
<tr>
<td align="center"><strong>collect</strong>()</td>
<td align="center">在驱动程序中，以数组的形式返回数据集的所有元素</td>
</tr>
<tr>
<td align="center"><strong>count</strong>()</td>
<td align="center">返回RDD的元素个数</td>
</tr>
<tr>
<td align="center"><strong>first</strong>()</td>
<td align="center">返回RDD的第一个元素（类似于take(1)）</td>
</tr>
<tr>
<td align="center"><strong>take</strong>(<em>n</em>)</td>
<td align="center">返回一个由数据集的前n个元素组成的数组</td>
</tr>
<tr>
<td align="center"><strong>takeSample</strong>(<em>withReplacement</em>,<em>num</em>, [<em>seed</em>])</td>
<td align="center">返回一个数组，该数组由从数据集中随机采样的num个元素组成，可以选择是否用随机数替换不足的部分，seed用于指定随机数生成器种子</td>
</tr>
<tr>
<td align="center"><strong>takeOrdered</strong>(<em>n</em>, <em>[ordering]</em>)</td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><strong>saveAsTextFile</strong>(<em>path</em>)</td>
<td align="center">将数据集的元素以textfile的形式保存到HDFS文件系统或者其他支持的文件系统，对于每个元素，Spark将会调用toString方法，将它装换为文件中的文本</td>
</tr>
<tr>
<td align="center"><strong>saveAsSequenceFile</strong>(<em>path</em>)</td>
<td align="center">将数据集中的元素以Hadoop sequencefile的格式保存到指定的目录下，可以使HDFS或者其他Hadoop支持的文件系统。</td>
</tr>
<tr>
<td align="center"><strong>saveAsObjectFile</strong>(<em>path</em>)</td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><strong>countByKey</strong>()</td>
<td align="center">针对(K,V)类型的RDD，返回一个(K,Int)的map，表示每一个key对应的元素个数。</td>
</tr>
<tr>
<td align="center"><strong>foreach</strong>(<em>func</em>)</td>
<td align="center">在数据集的每一个元素上，运行函数func进行更新。</td>
</tr>
<tr>
<td align="center"><strong>aggregate</strong></td>
<td align="center">先对分区进行操作，在总体操作</td>
</tr>
<tr>
<td align="center"><strong>reduceByKeyLocally</strong></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><strong>lookup、top、fold</strong></td>
<td align="center"></td>
</tr>
</tbody></table>
<p><strong>C、Spark WordCount代码编写</strong></p>
<p>使用maven进行项目构建</p>
<p>（1）使用scala进行编写</p>
<p>查看官方网站，需要导入2个依赖包</p>
<p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g5chb99yksj31ac0skwk4.jpg" alt="Tmp3">详细代码</p>
<p>SparkWordCountWithScala.scala</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkWordCountWithScala</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">      * 如果这个参数不设置，默认认为你运行的是集群模式</span></span><br><span class="line"><span class="comment">      * 如果设置成local代表运行的是local模式</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">    conf.setMaster(<span class="string">"local"</span>)</span><br><span class="line">    <span class="comment">//设置任务名</span></span><br><span class="line">    conf.setAppName(<span class="string">"WordCount"</span>)</span><br><span class="line">    <span class="comment">//创建SparkCore的程序入口</span></span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="comment">//读取文件 生成RDD</span></span><br><span class="line">    <span class="keyword">val</span> file: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">"E:\\hello.txt"</span>)</span><br><span class="line">    <span class="comment">//把每一行数据按照，分割</span></span><br><span class="line">    <span class="keyword">val</span> word: <span class="type">RDD</span>[<span class="type">String</span>] = file.flatMap(_.split(<span class="string">","</span>))</span><br><span class="line">    <span class="comment">//让每一个单词都出现一次</span></span><br><span class="line">    <span class="keyword">val</span> wordOne: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = word.map((_,<span class="number">1</span>))</span><br><span class="line">    <span class="comment">//单词计数</span></span><br><span class="line">    <span class="keyword">val</span> wordCount: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordOne.reduceByKey(_+_)</span><br><span class="line">    <span class="comment">//按照单词出现的次数 降序排序</span></span><br><span class="line">    <span class="keyword">val</span> sortRdd: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordCount.sortBy(tuple =&gt; tuple._2,<span class="literal">false</span>)</span><br><span class="line">    <span class="comment">//将最终的结果进行保存</span></span><br><span class="line">    sortRdd.saveAsTextFile(<span class="string">"E:\\result"</span>)</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>运行结果</p>
<p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g5chdemdk2j30da09gwer.jpg" alt="Tmp4"></p>
<p>（2）使用java jdk8进行编写</p>
<p>lambda表达式</p>
<p>SparkWordCountWithJava8.java</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaPairRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> scala.Tuple2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SparkWordCountWithJava8</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SparkConf conf = <span class="keyword">new</span> SparkConf();</span><br><span class="line">        conf.setAppName(<span class="string">"WortCount"</span>);</span><br><span class="line">        conf.setMaster(<span class="string">"local"</span>);</span><br><span class="line">        JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(conf);</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;String&gt; fileRDD = sc.textFile(<span class="string">"E:\\hello.txt"</span>);</span><br><span class="line">        JavaRDD&lt;String&gt; wordRdd = fileRDD.flatMap(line -&gt; Arrays.asList(line.split(<span class="string">","</span>)).iterator());</span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; wordOneRDD = wordRdd.mapToPair(word -&gt; <span class="keyword">new</span> Tuple2&lt;&gt;(word, <span class="number">1</span>));</span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; wordCountRDD = wordOneRDD.reduceByKey((x, y) -&gt; x + y);</span><br><span class="line">        JavaPairRDD&lt;Integer, String&gt; count2WordRDD = wordCountRDD.mapToPair(tuple -&gt; <span class="keyword">new</span> Tuple2&lt;&gt;(tuple._2, tuple._1));</span><br><span class="line">        JavaPairRDD&lt;Integer, String&gt; sortRDD = count2WordRDD.sortByKey(<span class="keyword">false</span>);</span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; resultRDD = sortRDD.mapToPair(tuple -&gt; <span class="keyword">new</span> Tuple2&lt;&gt;(tuple._2, tuple._1));</span><br><span class="line">        resultRDD.saveAsTextFile(<span class="string">"E:\\result8"</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p><strong>D、WordCount执行过程图</strong></p>
<p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g5chggq4anj30xa0u00xq.jpg" alt="Tmp5"></p>
<p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g5chhg53a1j310j0u0div.jpg" alt="Tmp6"></p>
<h2 id="四、RDD的宽依赖和窄依赖"><a href="#四、RDD的宽依赖和窄依赖" class="headerlink" title="四、RDD的宽依赖和窄依赖"></a>四、RDD的宽依赖和窄依赖</h2><p><strong>A、RDD依赖关系的本质内幕</strong></p>
<p>由于RDD是粗粒度的操作数据集，每个Transformation操作都会生成一个新的RDD，所以RDD之间就会形成类似流水线的前后依赖关系；RDD和它依赖的父RDD（s）的关系有两种不同的类型，即窄依赖（narrow dependency）和宽依赖（wide dependency）。如图所示显示了RDD之间的依赖关系。</p>
<p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g5chkiow63j30pm0gy0uu.jpg" alt="Tmp8"></p>
<p>从图中可知：</p>
<p><strong>窄依赖：</strong>是指每个父RDD的一个Partition最多被子RDD的一个Partition所使用，例如map、filter、union等操作都会产生窄依赖；（独生子女）</p>
<p><strong>宽依赖：</strong>是指一个父RDD的Partition会被多个子RDD的Partition所使用，例如groupByKey、reduceByKey、sortByKey等操作都会产生宽依赖；（超生）</p>
<p>需要特别说明的是对join操作有两种情况：</p>
<p>（1）图中左半部分join：如果两个RDD在进行join操作时，一个RDD的partition仅仅和另一个RDD中已知个数的Partition进行join，那么这种类型的join操作就是窄依赖，例如图1中左半部分的join操作(join with inputs co-partitioned)；</p>
<p>（2）图中右半部分join：其它情况的join操作就是宽依赖,例如图1中右半部分的join操作(join with inputs not co-partitioned)，由于是需要父RDD的所有partition进行join的转换，这就涉及到了shuffle，因此这种类型的join操作也是宽依赖。</p>
<p>总结：</p>
<blockquote>
<p>在这里我们是从父RDD的partition被使用的个数来定义窄依赖和宽依赖，因此可以用一句话概括下：如果父RDD的一个Partition被子RDD的一个Partition所使用就是窄依赖，否则的话就是宽依赖。因为是确定的partition数量的依赖关系，所以RDD之间的依赖关系就是窄依赖；由此我们可以得出一个推论：即窄依赖不仅包含一对一的窄依赖，还包含一对固定个数的窄依赖。</p>
<p>一对固定个数的窄依赖的理解：即子RDD的partition对父RDD依赖的Partition的数量不会随着RDD数据规模的改变而改变；换句话说，无论是有100T的数据量还是1P的数据量，在窄依赖中，子RDD所依赖的父RDD的partition的个数是确定的，而宽依赖是shuffle级别的，数据量越大，那么子RDD所依赖的父RDD的个数就越多，从而子RDD所依赖的父RDD的partition的个数也会变得越来越多。</p>
</blockquote>
<p><strong>B、依赖关系下的数据流视图</strong></p>
<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g5chlnynazj30ya0ladiw.jpg" alt="Tmp7"></p>
<p>在spark中，会根据RDD之间的依赖关系将DAG图（有向无环图）划分为不同的阶段，对于窄依赖，由于partition依赖关系的确定性，partition的转换处理就可以在同一个线程里完成，窄依赖就被spark划分到同一个stage中，而对于宽依赖，只能等父RDD shuffle处理完成后，下一个stage才能开始接下来的计算。</p>
<p><strong>因此spark划分stage的整体思路是</strong>：从后往前推，遇到宽依赖就断开，划分为一个stage；遇到窄依赖就将这个RDD加入该stage中。因此在图2中RDD C,RDD D,RDD E,RDDF被构建在一个stage中,RDD A被构建在一个单独的Stage中,而RDD B和RDD G又被构建在同一个stage中。</p>
<p>在spark中，Task的类型分为2种：<strong>ShuffleMapTask</strong>和<strong>ResultTask</strong>；</p>
<p>简单来说，DAG的最后一个阶段会为每个结果的partition生成一个ResultTask，即每个Stage里面的Task的数量是由该Stage中最后一个RDD的Partition的数量所决定的！而其余所有阶段都会生成ShuffleMapTask；之所以称之为ShuffleMapTask是因为它需要将自己的计算结果通过shuffle到下一个stage中；也就是说上图中的stage1和stage2相当于mapreduce中的Mapper,而ResultTask所代表的stage3就相当于mapreduce中的reducer。</p>
<p>在之前动手操作了一个wordcount程序，因此可知，Hadoop中MapReduce操作中的Mapper和Reducer在spark中的基本等量算子是map和reduceByKey;不过区别在于：Hadoop中的MapReduce天生就是排序的；而reduceByKey只是根据Key进行reduce，但spark除了这两个算子还有其他的算子；因此从这个意义上来说，Spark比Hadoop的计算算子更为丰富。</p>

      
    </div>
    
    
    

    <div>
    
        
    
    </div>

    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>

      
    </div>


    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>大 吉 大 利！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechat.jpg" alt="想当校长的老王 微信支付">
        <p>微信支付</p>
      </div>
    

    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    想当校长的老王
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://yoursite.com/2019/07/25/Spark学习之路（二）Spark之RDD/" title="Spark学习之路（二）Spark之RDD">http://yoursite.com/2019/07/25/Spark学习之路（二）Spark之RDD/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/RDD/" rel="tag"><i class="fa fa-tag"></i> RDD</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/07/25/Spark学习之路（一）Spark初识/" rel="next" title="Spark学习之路（一）Spark初识">
                <i class="fa fa-chevron-left"></i> Spark学习之路（一）Spark初识
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="想当校长的老王">
            
              <p class="site-author-name" itemprop="name">想当校长的老王</p>
              <p class="site-description motion-element" itemprop="description">愿能阅尽天下事，洗手仍能做羹汤</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/Co-Hwang" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://mail.163.com/" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#一、RDD概述"><span class="nav-number">1.</span> <span class="nav-text">一、RDD概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、RDD创建方式"><span class="nav-number">2.</span> <span class="nav-text">二、RDD创建方式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#三、RDD编程API"><span class="nav-number">3.</span> <span class="nav-text">三、RDD编程API</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#四、RDD的宽依赖和窄依赖"><span class="nav-number">4.</span> <span class="nav-text">四、RDD的宽依赖和窄依赖</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">这個人好蠢、</span>

  
</div>

<!--
  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>
-->



        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访客数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 浏览量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  





  
  







  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
