<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">

<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="优化,">










<meta name="description" content="Hive总结及优化 &amp;emsp;&amp;emsp;官网地址：Hive Wiki         参考博客：爆发的小宇宙   &amp;emsp;&amp;emsp;Hive是一个构建在Hadoop之上的数据仓库软件,它可以使已经存储的数据结构化，它提供类似sql的查询语句HiveQL对数据进行分析处理。 Hive将HiveQL语句转换成一系列成MapReduce作业并执行（SQL转化为MapReduce的过程）。用户可">
<meta name="keywords" content="优化">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive学习之路（二）Hive总结及优化">
<meta property="og:url" content="http://yoursite.com/2019/07/15/Hive学习之路（二）Hive总结及优化/index.html">
<meta property="og:site_name" content="这個人好蠢、">
<meta property="og:description" content="Hive总结及优化 &amp;emsp;&amp;emsp;官网地址：Hive Wiki         参考博客：爆发的小宇宙   &amp;emsp;&amp;emsp;Hive是一个构建在Hadoop之上的数据仓库软件,它可以使已经存储的数据结构化，它提供类似sql的查询语句HiveQL对数据进行分析处理。 Hive将HiveQL语句转换成一系列成MapReduce作业并执行（SQL转化为MapReduce的过程）。用户可">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://ww3.sinaimg.cn/large/006tNc79ly1g50l4ccl3aj31320noabr.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79ly1g50n64yge1j312u0rywhh.jpg">
<meta property="og:updated_time" content="2019-07-26T12:31:07.246Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hive学习之路（二）Hive总结及优化">
<meta name="twitter:description" content="Hive总结及优化 &amp;emsp;&amp;emsp;官网地址：Hive Wiki         参考博客：爆发的小宇宙   &amp;emsp;&amp;emsp;Hive是一个构建在Hadoop之上的数据仓库软件,它可以使已经存储的数据结构化，它提供类似sql的查询语句HiveQL对数据进行分析处理。 Hive将HiveQL语句转换成一系列成MapReduce作业并执行（SQL转化为MapReduce的过程）。用户可">
<meta name="twitter:image" content="http://ww3.sinaimg.cn/large/006tNc79ly1g50l4ccl3aj31320noabr.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/07/15/Hive学习之路（二）Hive总结及优化/">





  <title>Hive学习之路（二）Hive总结及优化 | 这個人好蠢、</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <a href="https://github.com/Co-Hwang"><img style="position: absolute; top: 0; left: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_left_red_aa0000.png" alt="Fork me on GitHub"></a>


    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">这個人好蠢、</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">哪懂坚持 | 全靠死撑</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>




<script>
  
  window.onload = function(){
    var path = 'https://Co-Hwang.github.io'; //
    var localhostItem = String(window.location).split(path)[1];
    var LiNode = document.querySelectorAll('#menu > li > a')
    
    for(var i = 0; i< LiNode.length;i++){
      var item = String(LiNode[i].href).split(path)[1];
      if(item == localhostItem && item != undefined){
        LiNode[i].setAttribute('style','border-bottom:1px solid black');
      }
    }
  };

</script>
 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/15/Hive学习之路（二）Hive总结及优化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="想当校长的老王">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="这個人好蠢、">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Hive学习之路（二）Hive总结及优化</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-15T15:35:13+08:00">
                2019-07-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hive/" itemprop="url" rel="index">
                    <span itemprop="name">Hive</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  8.5k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  32 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><font size="5"><strong>Hive总结及优化</strong></font></p>
<p>&emsp;&emsp;官网地址：<a href="http://hive.apache.org/" target="_blank" rel="noopener">Hive Wiki</a>         参考博客：<a href="https://blog.csdn.net/yu0_zhang0/article/details/81776459" target="_blank" rel="noopener">爆发的小宇宙</a>  </p>
<p>&emsp;&emsp;<strong>Hive是一个构建在Hadoop之上的数据仓库软件,它可以使已经存储的数据结构化，它提供类似sql的查询语句HiveQL对数据进行分析处理。 Hive将HiveQL语句转换成一系列成MapReduce作业并执行（SQL转化为MapReduce的过程）。用户可以很方便的使用命令行和JDBC程序的方式来连接到hive。 目前，Hive除了支持MapReduce计算引擎，还支持Spark和Tez这两中分布式计算引擎。常用于离线批处理。</strong></p>
<a id="more"></a>

<h2 id="一、产生背景"><a href="#一、产生背景" class="headerlink" title="一、产生背景"></a>一、产生背景</h2><p>&emsp;&emsp;大数据的时代，海量的数据对于传统的关系型数据库来说维护起来成本非常高，那该如何是好，Hadoop分布式的框架，可以使用廉价的机器部署分布式系统把数据存储再HDFS之上，通过MR进行计算，分析，这样是可以的，但是，MR大家应该知道，MapReduce编程带来的不便性，编程十分繁琐，在大多情况下，每个MapReduce程序需要包含Mapper、Reducer和一个Driver，之后需要打成jar包扔到集群上运行。如果mr写完之后，且该项目已经上线，一旦业务逻辑发生了改变，可能就会带来大规模的改动代码，然后重新打包，发布，非常麻烦(这种方式，也是最古老的方式)，当大量数据都存放在HDFS上，如何快速的对HDFS上的文件进行统计分析操作？<br>&emsp;&emsp;一般来说，想要做会有两种方式：</p>
<p>&emsp;&emsp;A、学Java、学MapReduce(十分麻烦)</p>
<p>&emsp;&emsp;B、做DBA的：写SQL(希望能通过写SQL这样的方式来实现，这种方式较好)</p>
<p>&emsp;&emsp;然而，HDFS中最关键的一点就是，数据存储HDFS上是没有schema的概念的(schema：相当于表里面有列、字段、字段名称、字段与字段之间的分隔符等，这些就是schema信息)，然而HDFS上的仅仅只是一个纯的文本文件而已，那么，没有schema，就没办法使用sql进行查询了啊。。。因此，在这种背景下，就有问题产生：如何为HDFS上的文件添加Schema信息？如果加上去，是否就可以通过SQL的方式进行处理了呢？于是强大的Hive出现了。</p>
<h2 id="二、Hive深入剖析"><a href="#二、Hive深入剖析" class="headerlink" title="二、Hive深入剖析"></a>二、Hive深入剖析</h2><p>&emsp;&emsp;再来看看官网给我们的介绍：官方第一句话就说明了Apache Hive 是<strong>构建在Apache Hadoop之上的数据仓库，有助于对大型的数据集进行读、写和管理。</strong></p>
<p>&emsp;&emsp;那我们先对这句话进行剖析：</p>
<p>&emsp;&emsp;首先Hive是构建在Hadoop之上的，其实就是Hive中的数据其实是存储再HDFS上的（加上LOCAL关键字则是在本地），默认在<code>/user/hive/warehouse/table</code>,有助于对大型数据集进行读、写和管理，那也就是意味着传统的关系型数据库已经无法满足现在的数据量了，需要一个更大的仓库来帮助我们存储，这里也引出一个问题：<strong>Hive和关系型数据库的区别</strong>，后面我们再来聊。</p>
<h3 id="1、Hive的特征："><a href="#1、Hive的特征：" class="headerlink" title="1、Hive的特征："></a>1、Hive的特征：</h3><p>&emsp;&emsp;<strong>A、</strong>可通过SQL轻松访问数据的工具，从而实现数据仓库任务，如提取/转换/加载（ETL），报告和数据分析。</p>
<p>&emsp;&emsp;<strong>B、</strong>它可以使已经存储的数据结构化</p>
<p>&emsp;&emsp;<strong>C、</strong>可以直接访问存储在Apache HDFS™或其他数据存储系统（如Apache HBase™）中的文件</p>
<p>&emsp;&emsp;<strong>D、</strong>Hive除了支持MapReduce计算引擎，还支持Spark和Tez这两中分布式计算引擎（这里会引申出一个问题，哪些查询跑mr哪些不跑？）</p>
<p>&emsp;&emsp;<strong>E、</strong>它提供类似sql的查询语句HiveQL对数据进行分析处理。</p>
<p>&emsp;&emsp;<strong>F、</strong>数据的存储格式有多种，比如数据源是二进制格式， 普通文本格式等等</p>
<p>&emsp;&emsp;而Hive强大之处不要求数据转换成特定的格式，而是利用hadoop本身InputFormat API来从不同的数据源读取数据，同样地使用OutputFormat API将数据写成不同的格式。所以对于不同的数据源，或者写出不同的格式就需要不同的对应的InputFormat和Outputformat类的实现。</p>
<p>&emsp;&emsp;以<strong>stored as textfile</strong>为例，其在底层java API中表现是输入InputFormat格式：TextInputFormat以及输出OutputFormat格式：HiveIgnoreKeyTextOutputFormat。这里InputFormat中定义了如何对数据源文本进行读取划分，以及如何将切片分割成记录存入表中。而Outputformat定义了如何将这些切片写回到文件里或者直接在控制台输出。</p>
<p>&emsp;&emsp;不仅如此Hive的SQL还可以通过用户定义的函数（UDF），用户定义的聚合（UDAF）和用户定义的表函数（UDTF）进行扩展。几个函数之间的区别？？？Hive中不仅可以使用逗号和制表符分隔值（CSV / TSV）文本文件，还可以使用Sequence File、RC、ORC、Parquet （<a href="https://blog.csdn.net/colorant/article/details/53699822" target="_blank" rel="noopener">知道这几种存储格式的区别</a>）。</p>
<p>&emsp;&emsp;<strong>A、</strong>在压缩存储时间上，除Sequencefile外基本都相差无几。</p>
<p>&emsp;&emsp;<strong>B、</strong>数据压缩比例上ORC最优，相比textfile节省了50倍磁盘空间，parquet压缩性能也较好。</p>
<p>&emsp;&emsp;<strong>C、</strong>SQL查询速度而言，ORC与parquet性能较好，远超其余存储格式。</p>
<p>&emsp;&emsp;综合上述各种性能指标，建议工作中原始日志写入hive的存储格式都采用ORC或者parquet格式，这和目前主流的做法一致。</p>
<p>&emsp;&emsp;当然Hive还可以通过用户来自定义自己的存储格式，基本上前面说的到的几种格式完全够了。Hive旨在最大限度地提高可伸缩性（通过向Hadoop集群动态添加更多机器扩展），性能，可扩展性，容错性以及与其输入格式的松散耦合。</p>
<h3 id="2、Hive基本语法"><a href="#2、Hive基本语法" class="headerlink" title="2、Hive基本语法"></a>2、Hive基本语法</h3><p>&emsp;&emsp;可以参考之前的博客总结。<a href="https://co-hwang.github.io/2019/07/04/HiveSQL语法/" target="_blank" rel="noopener">HiveSQL语法&lt;基本原理、操作函数&gt;</a></p>
<p>&emsp;&emsp;<strong>Hive的存储结构如下：</strong></p>
<p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g50l4ccl3aj31320noabr.jpg" alt="Hive的数据存储结构"></p>
<p>&emsp;&emsp;<strong>A、</strong>Database：Hive中包含了多个数据库，默认的数据库为default，对应于HDFS目录是<code>/user/hadoop/hive/warehouse</code>，可以通过<code>hive.metastore.warehouse.dir</code>参数进行配置（hive-site.xml中配置） </p>
<p>&emsp;&emsp;<strong>B、</strong>Table: Hive 中的表又分为内部表和外部表 ,Hive 中的每张表对应于HDFS上的一个目录，HDFS目录为：<code>/user/hadoop/hive/warehouse/[databasename.db]/table</code> 。 </p>
<p>&emsp;&emsp;<strong>C、</strong>Partition:分区，每张表中可以加入一个分区或者多个，方便查询，提高效率；并且HDFS上会有对应的分区目录：<code>/user/hadoop/hive/warehouse/[databasename.db]/table</code> </p>
<p>&emsp;&emsp;<strong>D、</strong>Bucket：….待续（未完成）</p>
<p>&emsp;&emsp;<strong>UDF函数这里要进行一个讲解UDF、DUAF、UDTF分别是啥？</strong></p>
<p>&emsp;&emsp;我们知道Hive的SQL还可以通过用户定义的函数（UDF），用户定义的聚合（UDAF）和用户定义的表函数（UDTF）进行扩展。当Hive提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数（UDF：user-defined function）。　　</p>
<p>&emsp;&emsp;<strong>A、</strong>UDF(User-Defined-Function) 一进一出</p>
<p>&emsp;&emsp;<strong>B、</strong>UDAF(User- Defined Aggregation Funcation) 聚集函数，多进一出。</p>
<p>&emsp;&emsp;<strong>C、</strong>UDTF(User-Defined Table-Generating Functions) 一进多出，如：lateral view explore()</p>
<h3 id="3、Hive与关系型数据库的区别"><a href="#3、Hive与关系型数据库的区别" class="headerlink" title="3、Hive与关系型数据库的区别"></a>3、Hive与关系型数据库的区别</h3><p>&emsp;&emsp;<strong>A、</strong>时效性、延时性比较高，可扩展性高；</p>
<p>&emsp;&emsp;<strong>B、</strong>Hive数据规模大，优势在于处理大数据集，对于小数据集没有优势</p>
<p>&emsp;&emsp;<strong>C、</strong>事务没什么用(比较鸡肋，没什么实际的意义，对于离线的来说)  一个小问题：那个版本开始提供了事务？</p>
<p>&emsp;&emsp;<strong>D、</strong>insert/update没什么实际用途，大数据场景下大多数是select</p>
<p>&emsp;&emsp;<strong>E、</strong>RDBMS也支持分布式，节点有限 成本高，处理的数据量小</p>
<p>&emsp;&emsp;<strong>F、</strong>Hadoop集群规模更大 部署在廉价机器上，处理的数据量大</p>
<p>&emsp;&emsp;<strong>G、</strong>数据库可以用在Online的应用中，Hive主要进行离线的大数据分析；</p>
<p>&emsp;&emsp;<strong>H、</strong>数据库的查询语句为SQL，Hive的查询语句为HQL；</p>
<p>&emsp;&emsp;<strong>I、</strong>数据库数据存储在LocalFS，Hive的数据存储在HDFS；</p>
<p>&emsp;&emsp;<strong>J、</strong>数据格式：Hive中有多种存储格式，由于在加载数据的过程中，不需要从用户数据格式到 Hive 定义的数据格式的转换，因此，Hive 在加载的过程中不会对数据本身进行任何修改，而只是将数据内容复制或者移动到相应的 HDFS 目录中。而在数据库中，不同的数据库有不同的存储引擎，定义了自己的数据格式。所有数据都会按照一定的组织存储，因此，数据库加载数据的过程会比较耗时。</p>
<p>&emsp;&emsp;<strong>K、</strong>Hive执行MapReduce，MySQL执行Executor；</p>
<h3 id="4、Hive的优点"><a href="#4、Hive的优点" class="headerlink" title="4、Hive的优点"></a>4、Hive的优点</h3><p>&emsp;&emsp;<strong>A、</strong>简单易上手</p>
<p>&emsp;&emsp;<strong>B、</strong>扩展能力较好(指集群 HDFS或是YARN)</p>
<p>&emsp;&emsp;<strong>C、</strong>统一的元数据管理 metastore包括的了数据库，表，字段分区等详细信息</p>
<p>&emsp;&emsp;<strong>D、</strong>由于统一的元数据管理所以和spark/impala等SQL引擎是通用的，通用是指，在拥有了统一的metastore之后，在Hive中创建一张表，在Spark/impala中是能用的，反之在Spark中创建一张表，在Hive中也能用；只需要共用元数据，就可以切换SQL引擎。涉及到了Spark sql 和Hive On Spark(实验版本)</p>
<p>&emsp;&emsp;<strong>E、</strong>使用SQL语法，提供快速开发的能力，支持自定义函数UDF。</p>
<p>&emsp;&emsp;<strong>F、</strong>避免了去写mapreduce，减少开发人员学习成本。</p>
<p>&emsp;&emsp;<strong>G、</strong>数据离线处理，比如日志分析，海量数据结构化分析</p>
<h3 id="5、SQL转化为MapReduce的过程"><a href="#5、SQL转化为MapReduce的过程" class="headerlink" title="5、SQL转化为MapReduce的过程"></a>5、SQL转化为MapReduce的过程</h3><p>&emsp;&emsp;了解了MapReduce实现SQL基本操作之后，我们来看看Hive是如何将SQL转化为MapReduce任务的，整个编译过程分为六个阶段：</p>
<p>&emsp;&emsp;<strong>A、</strong>Antlr定义SQL的语法规则，完成SQL词法，语法解析，将SQL转化为抽象语法树AST Tree</p>
<p>&emsp;&emsp;<strong>B、</strong>遍历AST Tree，抽象出查询的基本组成单元QueryBlock</p>
<p>&emsp;&emsp;<strong>C、</strong>遍历QueryBlock，翻译为执行操作树OperatorTree</p>
<p>&emsp;&emsp;<strong>D、</strong>逻辑层优化器进行OperatorTree变换，合并不必要的ReduceSinkOperator，减少shuffle数据量</p>
<p>&emsp;&emsp;<strong>E、</strong>遍历OperatorTree，翻译为MapReduce任务</p>
<p>&emsp;&emsp;<strong>F、</strong>物理层优化器进行MapReduce任务的变换，生成最终的执行计划</p>
<p>&emsp;&emsp;<strong>美团技术：</strong><a href="https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html" target="_blank" rel="noopener">HiveSQL编译过程</a></p>
<h3 id="6、Hive内部表和外部表的区别"><a href="#6、Hive内部表和外部表的区别" class="headerlink" title="6、Hive内部表和外部表的区别"></a>6、Hive内部表和外部表的区别</h3><p>&emsp;&emsp;未被external修饰的是内部表（managed table），被external修饰的为外部表（external table）；</p>
<p>&emsp;&emsp;<strong>区别：</strong></p>
<p>&emsp;&emsp;<strong>A、</strong>内部表数据由Hive自身管理，外部表数据由HDFS管理；</p>
<p>&emsp;&emsp;<strong>B、</strong>内部表数据存储的位置是hive.metastore.warehouse.dir（默认：<code>/user/hive/warehouse</code>），外部表数据的存储位置由自己制定；</p>
<p>&emsp;&emsp;<strong>C、</strong>删除内部表会直接删除元数据（metadata）及存储数据；删除外部表仅仅会删除元数据，HDFS上的文件并不会被删除；</p>
<h3 id="7、行式存储vs列式存储"><a href="#7、行式存储vs列式存储" class="headerlink" title="7、行式存储vs列式存储"></a>7、行式存储vs列式存储</h3><p>&emsp;&emsp;行式数据库存储在hdfs上式按行进行存储的，一个block存储一或多行数据。而列式数据库在hdfs上则是按照列进行存储，一个block可能有一列或多列数据。</p>
<p>&emsp;&emsp;<strong>如果要将数据进行压缩：</strong></p>
<p>&emsp;&emsp;<strong>A、</strong>对于行式数据库，必然按行压缩，当一行中有多个字段，各个字段对应的数据类型可能不一致，压缩性能压缩比就比较差。</p>
<p>&emsp;&emsp;<strong>B、</strong>对于列式数据库，必然按列压缩，每一列对应的是相同数据类型的数据，故列式数据库的压缩性能要强于行式数据库。</p>
<p>&emsp;&emsp;<strong>如果要进行数据的查询：</strong></p>
<p>&emsp;&emsp;假设执行的查询操作是：<code>select id,name from table_emp;</code></p>
<p>&emsp;&emsp;<strong>A、</strong>对于行式数据库，它要遍历一整张表将每一行中的id，name字段拼接再展现出来，这样需要查询的数据量就比较大，效率低。</p>
<p>&emsp;&emsp;<strong>B、</strong>对于列式数据库，它只需找到对应的id,name字段的列展现出来即可，需要查询的数据量小，效率高。</p>
<p>&emsp;&emsp;假设执行的查询操作是：select * from table_emp;</p>
<p>&emsp;&emsp;对于这种查询整个表全部信息的操作，由于列式数据库需要将分散的行进行重新组合，行式数据库效率就高于列式数据库。</p>
<p>&emsp;&emsp;但是，在大数据领域，进行全表查询的场景少之又少，进而我们使用较多的还是列式数据库及列式储存。</p>
<h3 id="8、Hive哪些查询会执行MR"><a href="#8、Hive哪些查询会执行MR" class="headerlink" title="8、Hive哪些查询会执行MR"></a>8、Hive哪些查询会执行MR</h3><p>&emsp;&emsp;Hive 0.10.0为了执行效率考虑，简单的查询，就是只是select，不带count,sum,group by这样的，都不走map/reduce，直接读取hdfs文件进行filter过滤。<strong>这样做的好处</strong>就是不新开mr任务，执行效率要提高不少，但是不好的地方就是用户界面不友好，有时候数据量大还是要等很长时间，但是又没有任何返回。</p>
<p>&emsp;&emsp;改这个很简单，在hive-site.xml里面有个配置参数叫<code>hive.fetch.task.conversion</code>，将这个参数设置为more，简单查询就不走map/reduce了，设置为minimal，就任何简单select都会走map/reduce</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Create</span> <span class="keyword">Table</span> <span class="keyword">As</span> <span class="keyword">Select</span> (CTAS) 走mr</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> emp2 <span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> 一条或者多条 走mr</span><br></pre></td></tr></table></figure>

<h3 id="9、Hive静态分区、动态分区"><a href="#9、Hive静态分区、动态分区" class="headerlink" title="9、Hive静态分区、动态分区"></a>9、Hive静态分区、动态分区</h3><p>&emsp;&emsp;<strong>A、分区的概念</strong></p>
<p>&emsp;&emsp;Hive的分区方式：由于Hive实际是存储在HDFS上的抽象，Hive的一个分区名对应HDFS上的一个目录名，子分区名就是子目录名，并不是一个实际字段。</p>
<p>&emsp;&emsp;<strong>B、分区的好处</strong></p>
<p>&emsp;&emsp;产生背景：如果一个表中数据很多，我们查询时就很慢，耗费大量时间，如果要查询其中部分数据该怎么办呢，这是我们引入分区的概念。</p>
<p>&emsp;&emsp;Partition：分区，每张表中可以加入一个分区或者多个，方便查询，提高效率；并且HDFS上会有对应的分区目录：</p>
<p>&emsp;&emsp;<strong>C、语法</strong></p>
<p>&emsp;&emsp;Hive分区是在创建表的时候用Partitioned by 关键字定义的，但要注意，Partitioned by子句中定义的列是表中正式的列，但是Hive下的数据文件中并不包含这些列，因为它们是目录名，真正的数据在分区目录下。</p>
<p>&emsp;<strong>&emsp;D、静态分区 和 动态分区的区别</strong></p>
<p>&emsp;&emsp;创建表的语法都一样</p>
<p>&emsp;&emsp;静态分区：加载数据的时候要指定分区的值（key=value），比较麻烦的是每次插入数据都要指定分区的值，创建多个分区多分区一样，以逗号分隔。</p>
<p>&emsp;&emsp;动态分区：如果用上述的静态分区，插入的时候必须首先要知道有什么分区类型，而且每个分区写一个load data，太烦人。使用动态分区可解决以上问题，其可以根据查询得到的数据动态分配到分区里。其实动态分区与静态分区区别就是不指定分区目录，由系统自己选择。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">首先，启动动态分区功能</span><br><span class="line"></span><br><span class="line">hive&gt; set hive.exec.dynamic.partition=true;</span><br><span class="line"></span><br><span class="line">采用动态方式加载数据到目标表 </span><br><span class="line">加载之前先设置一下下面的参数</span><br><span class="line"></span><br><span class="line">hive (default)&gt; set hive.exec.dynamic.partition.mode=nonstrict</span><br><span class="line">1</span><br><span class="line">开始加载</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> emp_dynamic_partition <span class="keyword">partition</span>(deptno)</span><br><span class="line"><span class="keyword">select</span> empno , ename , job , mgr , hiredate , sal , comm, deptno <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;加载数据方式并没有指定具体的分区，只是指出了分区字段。在select最后一个字段必须跟你的分区字段，这样就会自行根据deptno的value来分区。</p>
<h3 id="10、删除分区"><a href="#10、删除分区" class="headerlink" title="10、删除分区"></a>10、删除分区</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> my_partition_test_table <span class="keyword">DROP</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> <span class="keyword">PARTITION</span> (<span class="keyword">day</span>=<span class="string">'2019-07-15'</span>);</span><br></pre></td></tr></table></figure>

<h3 id="11、Hive优化"><a href="#11、Hive优化" class="headerlink" title="11、Hive优化"></a>11、Hive优化</h3><p>&emsp;&emsp;<strong>A、</strong>我们知道大数据场景下不害怕数据量大，害怕的是数据倾斜，怎样避免数据倾斜，找到可能产生数据倾斜的函数尤为关键，数据量较大的情况下，慎用count(distinct)，count(distinct)容易产生倾斜问题。</p>
<p>&emsp;&emsp;<strong>B、</strong>设置合理的map reduce 的task数量</p>
<p><font color="#dd0000"><strong>map阶段优化</strong></font></p>
<pre><code>mapred.min.split.size: 指的是数据的最小分割单元大小；min的默认值是1B
mapred.max.split.size: 指的是数据的最大分割单元大小；max的默认值是256MB
通过调整max可以起到调整map数的作用，减小max可以增加map数，增大max可以减少map数。
需要提醒的是，直接调整mapred.map.tasks这个参数是没有效果的。
举例：
a) 假设input目录下有1个文件a,大小为780M,那么hadoop会将该文件a分隔成7个块（6个128m的块和1个12m的块），从而产生7个map数
b) 假设input目录下有3个文件a,b,c,大小分别为10m，20m，130m，那么hadoop会分隔成4个块（10m,20m,128m,2m）,从而产生4个map数
即，如果文件大于块大小(128m),那么会拆分，如果小于块大小，则把该文件当成一个块。</code></pre><p>&emsp;&emsp;其实这就涉及到小文件的问题：如果一个任务有很多小文件（远远小于块大小128m）,则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。那么问题又来了。。是不是保证每个map处理接近128m的文件块，就高枕无忧了？</p>
<p>&emsp;&emsp;答案也是不一定。比如有一个127m的文件，正常会用一个map去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，</p>
<p>&emsp;&emsp;如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。</p>
<p>&emsp;&emsp;我们该如何去解决呢？？？</p>
<p>&emsp;&emsp;我们需要采取两种方式来解决：即减少map数和增加map数；</p>
<p>&emsp;&emsp;<strong>1）减少map数量</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">假设一个SQL任务：</span><br><span class="line"><span class="keyword">Select</span> <span class="keyword">count</span>(<span class="number">1</span>) <span class="keyword">from</span> popt_tbaccountcopy_mes <span class="keyword">where</span> pt = ‘<span class="number">2012</span><span class="number">-07</span><span class="number">-04</span>’;</span><br><span class="line">该任务的inputdir  /group/p_sdo_data/p_sdo_data_etl/pt/popt_tbaccountcopy_mes/pt=2012-07-04</span><br><span class="line">共有194个文件，其中很多是远远小于128m的小文件，总大小9G，正常执行会用194个map任务。</span><br><span class="line">Map总共消耗的计算资源： SLOTS_MILLIS_MAPS= 623,020</span><br><span class="line"></span><br><span class="line">我通过以下方法来在map执行前合并小文件，减少map数：</span><br><span class="line"><span class="keyword">set</span> mapred.max.split.size=<span class="number">100000000</span>;</span><br><span class="line"><span class="keyword">set</span> mapred.min.split.size.per.node=<span class="number">100000000</span>;</span><br><span class="line"><span class="keyword">set</span> mapred.min.split.size.per.rack=<span class="number">100000000</span>;</span><br><span class="line"><span class="keyword">set</span> hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br><span class="line">再执行上面的语句，用了74个map任务，map消耗的计算资源：SLOTS_MILLIS_MAPS= 333,500</span><br><span class="line">对于这个简单SQL任务，执行时间上可能差不多，但节省了一半的计算资源。</span><br><span class="line">大概解释一下，100000000表示100M, <span class="keyword">set</span> hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;这个参数表示执行前进行小文件合并，前面三个参数确定合并文件块的大小，大于文件块大小128m的，按照128m来分隔，小于128m,大于100m的，按照100m来分隔，把那些小于100m的（包括小文件和分隔大文件剩下的），进行合并,最终生成了74个块。</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;<strong>2）增大map数量</strong></p>
<p>&emsp;&emsp;如何适当的增加map数？ </p>
<p>&emsp;&emsp;当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">假设有这样一个任务：</span><br><span class="line">   <span class="keyword">Select</span> data_desc,</span><br><span class="line">          <span class="keyword">count</span>(<span class="number">1</span>),</span><br><span class="line">          <span class="keyword">count</span>(<span class="keyword">distinct</span> <span class="keyword">id</span>),</span><br><span class="line">          <span class="keyword">sum</span>(<span class="keyword">case</span> <span class="keyword">when</span> …),</span><br><span class="line">          <span class="keyword">sum</span>(<span class="keyword">case</span> <span class="keyword">when</span> ...),</span><br><span class="line">          <span class="keyword">sum</span>(…)</span><br><span class="line">  <span class="keyword">from</span> a <span class="keyword">group</span> <span class="keyword">by</span> data_desc</span><br><span class="line">如果表a只有一个文件，大小为<span class="number">120</span>M，但包含几千万的记录，如果用<span class="number">1</span>个<span class="keyword">map</span>去完成这个任务，</span><br><span class="line">肯定是比较耗时的，这种情况下，我们要考虑将这一个文件合理的拆分成多个，</span><br><span class="line">这样就可以用多个<span class="keyword">map</span>任务去完成。</span><br><span class="line">  <span class="keyword">set</span> mapred.reduce.tasks=<span class="number">10</span>;</span><br><span class="line">  <span class="keyword">create</span> <span class="keyword">table</span> a_1 <span class="keyword">as</span> </span><br><span class="line">  <span class="keyword">select</span> * <span class="keyword">from</span> a <span class="keyword">distribute</span> <span class="keyword">by</span> <span class="keyword">rand</span>(<span class="number">123</span>); </span><br><span class="line"></span><br><span class="line">这样会将a表的记录，随机的分散到包含10个文件的a_1表中，再用a_1代替上面sql中的a表，</span><br><span class="line">则会用10个map任务去完成。</span><br><span class="line">每个map任务处理大于12M（几百万记录）的数据，效率肯定会好很多。</span><br><span class="line"></span><br><span class="line">看上去，貌似这两种有些矛盾，一个是要合并小文件，一个是要把大文件拆成小文件，这点正是重点需要关注的地方，使单个map任务处理合适的数据量；</span><br></pre></td></tr></table></figure>

<p><font color="#dd0000"><strong>reduce阶段优化</strong></font></p>
<pre><code>Reduce的个数对整个作业的运行性能有很大影响。如果Reduce设置的过大，那么将会产生很多小文件，
对NameNode会产生一定的影响，
而且整个作业的运行时间未必会减少；如果Reduce设置的过小，那么单个Reduce处理的数据将会加大，
很可能会引起OOM异常。
如果设置了mapred.reduce.tasks/mapreduce.job.reduces参数，那么Hive会直接使用它的值作为Reduce的个数；
如果mapred.reduce.tasks/mapreduce.job.reduces的值没有设置（也就是-1），那么Hive会
根据输入文件的大小估算出Reduce的个数。
根据输入文件估算Reduce的个数可能未必很准确，因为Reduce的输入是Map的输出，而Map的输出可能会比输入要小，
所以最准确的数根据Map的输出估算Reduce的个数。</code></pre><p>&emsp;&emsp;<strong>1）Hive自己如何确定reduce数：</strong></p>
<p>&emsp;&emsp;reduce个数的设定极大影响任务执行效率，不指定reduce个数的情况下，Hive会猜测确定一个reduce个数，基于以下两个设定：</p>
<p>&emsp;&emsp;<code>hive.exec.reducers.bytes.per.reducer</code>（每个reduce任务处理的数据量，默认为1000^3=1G）</p>
<p>&emsp;&emsp;<code>hive.exec.reducers.max</code>（每个任务最大的reduce数，默认为999）</p>
<p>&emsp;&emsp;计算reducer数的公式很简单N=min(参数2，总输入数据量/参数1)。即，如果reduce的输入（map的输出）总大小不超过1G，那么只会有一个reduce任务；</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> pt,<span class="keyword">count</span>(<span class="number">1</span>) <span class="keyword">from</span> popt_tbaccountcopy_mes <span class="keyword">where</span> pt = <span class="string">'2012-07-04'</span> <span class="keyword">group</span> <span class="keyword">by</span> pt;</span><br><span class="line"></span><br><span class="line">/group/p_sdo_data/p_sdo_data_etl/pt/popt_tbaccountcopy_mes/pt=2012-07-04 总大小为9G多，因此这句有10个reduce</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;<strong>2）调整reduce个数方法一</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">调整hive.exec.reducers.bytes.per.reducer参数的值；</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer=<span class="number">500000000</span>; （500M）</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> pt,<span class="keyword">count</span>(<span class="number">1</span>) <span class="keyword">from</span> popt_tbaccountcopy_mes <span class="keyword">where</span> pt = <span class="string">'2012-07-04'</span> <span class="keyword">group</span> <span class="keyword">by</span> pt; 这次有20个reduce</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;<strong>3）调整reduce个数方法二</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapred.reduce.tasks = <span class="number">15</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> pt,<span class="keyword">count</span>(<span class="number">1</span>) <span class="keyword">from</span> popt_tbaccountcopy_mes <span class="keyword">where</span> pt = <span class="string">'2012-07-04'</span> <span class="keyword">group</span> <span class="keyword">by</span> pt;这次有15个reduce</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;<strong>4）reduce个数并不是越多越好</strong></p>
<p>&emsp;&emsp;同map一样，启动和初始化reduce也会消耗时间和资源；另外，有多少个reduce,就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；</p>
<p>&emsp;&emsp;<strong>5）什么情况下只有一个reduce</strong></p>
<p>&emsp;&emsp;很多时候你会发现任务中不管数据量多大，不管你有没有设置调整reduce个数的参数，任务中一直都只有一个reduce任务；其实只有一个reduce任务的情况，除了数据量小于<code>hive.exec.reducers.bytes.per.reducer</code>参数值的情况外，还有以下原因：</p>
<ul>
<li><input checked disabled type="checkbox"> 没有group by的汇总，比如把<code>select pt,count(1) from popt_tbaccountcopy_mes where pt = ‘2012-07-04’ group by pt;</code>写成<code>select count(1) from popt_tbaccountcopy_mes where pt = ‘2012-07-04’;</code> 这点非常常见，希望大家尽量改写。</li>
<li><input checked disabled type="checkbox"> 用了Order by</li>
<li><input checked disabled type="checkbox"> 有笛卡尔积，通常这些情况下，除了找办法来变通和避免，我暂时没有什么好的办法，因为这些操作都是全局的，所以hadoop不得不用一个reduce去完成；同样的，在设置reduce个数的时候也需要考虑这两个原则：使大数据量利用合适的reduce数；使单个reduce任务处理合适的数据量；</li>
</ul>
<p>&emsp;&emsp;<strong>6）合并小文件</strong></p>
<p>&emsp;&emsp;我们知道文件数目小，容易在文件存储端造成瓶颈，给 HDFS 带来压力，影响处理效率。对此，可以通过合并Map和Reduce的结果文件来消除这样的影响。</p>
<p>&emsp;&emsp;用于设置合并属性的参数有：</p>
<p>&emsp;&emsp;是否合并Map输出文件：hive.merge.mapfiles=true（默认值为真）</p>
<p>&emsp;&emsp;是否合并Reduce 端输出文件：hive.merge.mapredfiles=false（默认值为假）</p>
<p>&emsp;&emsp;合并文件的大小：hive.merge.size.per.task=256<em>1000</em>1000（默认值为 256000000）</p>
<h3 id="12、Hive优化之小文件问题及其解决方案"><a href="#12、Hive优化之小文件问题及其解决方案" class="headerlink" title="12、Hive优化之小文件问题及其解决方案"></a>12、Hive优化之小文件问题及其解决方案</h3><h4 id="小文件是如何产生的"><a href="#小文件是如何产生的" class="headerlink" title="小文件是如何产生的"></a>小文件是如何产生的</h4><ol>
<li><p>动态分区插入数据，产生大量的小文件，从而导致map数量剧增。</p>
</li>
<li><p>reduce数量越多，小文件也越多(reduce的个数和输出文件是对应的)。</p>
</li>
<li><p>数据源本身就包含大量的小文件。</p>
</li>
</ol>
<h4 id="小文件问题的影响"><a href="#小文件问题的影响" class="headerlink" title="小文件问题的影响"></a>小文件问题的影响</h4><ol>
<li>从Hive的角度看，小文件会开很多map，一个map开一个JVM去执行，所以这些任务的初始化，启动，执行会浪费大量的资源，严重影响性能。</li>
<li>在HDFS中，每个小文件对象约占150byte，如果小文件过多会占用大量内存。这样NameNode内存容量严重制约了集群的扩展。</li>
</ol>
<h4 id="小文件问题的解决方案"><a href="#小文件问题的解决方案" class="headerlink" title="小文件问题的解决方案"></a>小文件问题的解决方案</h4><p>&emsp;&emsp;<strong>A、从小文件产生的途经就可以从源头上控制小文件数量，方法如下：</strong></p>
<ol>
<li>使用Sequencefile作为表存储格式，不要用textfile，在一定程度上可以减少小文件。</li>
<li>减少reduce的数量(可以使用参数进行控制)。</li>
<li>少用动态分区，用时记得按distribute by分区。</li>
</ol>
<p>&emsp;&emsp;<strong>B、对于已有的小文件，我们可以通过以下几种方案解决</strong></p>
<ol>
<li>使用hadoop archive命令把小文件进行归档。</li>
<li>重建表，建表时减少reduce数量。</li>
<li>通过参数进行调节，设置map/reduce端的相关参数，如下：</li>
</ol>
<p>&emsp;&emsp;<strong>C、设置map输入合并小文件的相关参数：</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[java] view plain copy</span><br><span class="line"><span class="comment">//每个Map最大输入大小(这个值决定了合并后文件的数量)  </span></span><br><span class="line">set mapred.max.split.size=<span class="number">256000000</span>;    </span><br><span class="line"><span class="comment">//一个节点上split的至少的大小(这个值决定了多个DataNode上的文件是否需要合并)  </span></span><br><span class="line">set mapred.min.split.size.per.node=<span class="number">100000000</span>;  </span><br><span class="line"><span class="comment">//一个交换机下split的至少的大小(这个值决定了多个交换机上的文件是否需要合并)    </span></span><br><span class="line">set mapred.min.split.size.per.rack=<span class="number">100000000</span>;  </span><br><span class="line"><span class="comment">//执行Map前进行小文件合并  </span></span><br><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;   </span><br><span class="line"></span><br><span class="line">设置map输出和reduce输出进行合并的相关参数：</span><br><span class="line">[java] view plain copy</span><br><span class="line"><span class="comment">//设置map端输出进行合并，默认为true  </span></span><br><span class="line">set hive.merge.mapfiles = <span class="keyword">true</span>  </span><br><span class="line"><span class="comment">//设置reduce端输出进行合并，默认为false  </span></span><br><span class="line">set hive.merge.mapredfiles = <span class="keyword">true</span>  </span><br><span class="line"><span class="comment">//设置合并文件的大小  </span></span><br><span class="line">set hive.merge.size.per.task = <span class="number">256</span>*<span class="number">1000</span>*<span class="number">1000</span>  </span><br><span class="line"><span class="comment">//当输出文件的平均大小小于该值时，启动一个独立的MapReduce任务进行文件merge。  </span></span><br><span class="line">set hive.merge.smallfiles.avgsize=<span class="number">16000000</span></span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;<strong>D、Write good SQL</strong></p>
<p>&emsp;&emsp;<strong>E、存储格式</strong></p>
<p>&emsp;&emsp;可以使用列裁剪，分区裁剪，orc，parquet等存储格式。参考<a href="https://blog.csdn.net/yu0_zhang0/article/details/79538398" target="_blank" rel="noopener">Hive中的存储格式</a>    </p>
<p>&emsp;&emsp;Hive支持ORCfile，这是一种新的表格存储格式，通过诸如谓词下推，压缩等技术来提高执行速度提升。对于每个HIVE表使用ORCFile应该是一件容易的事情，并且对于获得HIVE查询的快速响应时间非常有益。</p>
<p>&emsp;&emsp;作为一个例子，考虑两个大表A和B（作为文本文件存储，其中一些列未在此处指定，即行试存储的缺点）以及一个简单的查询，如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> A.customerID, A.name, A.age, A.address <span class="keyword">join</span></span><br><span class="line"></span><br><span class="line">B.role, B.department, B.salary</span><br><span class="line"></span><br><span class="line"><span class="keyword">ON</span> A.customerID=B.customerID;</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;此查询可能需要很长时间才能执行，因为表A和B都以TEXT形式存储，进行全表扫描。将这些表格转换为ORCFile格式通常会显着减少查询时间：ORC支持压缩存储（使用ZLIB或如上所示使用SNAPPY），但也支持未压缩的存储。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> A_ORC (</span><br><span class="line">customerID <span class="built_in">int</span>, <span class="keyword">name</span> <span class="keyword">string</span>, age <span class="built_in">int</span>, address <span class="keyword">string</span></span><br><span class="line">) <span class="keyword">STORED</span> <span class="keyword">AS</span> ORC tblproperties (“orc.compress<span class="string">" = “SNAPPY”);</span></span><br><span class="line"><span class="string">INSERT INTO TABLE A_ORC SELECT * FROM A;</span></span><br><span class="line"><span class="string">CREATE TABLE B_ORC (</span></span><br><span class="line"><span class="string">customerID int, role string, salary float, department string</span></span><br><span class="line"><span class="string">) STORED AS ORC tblproperties (“orc.compress"</span> = “SNAPPY”);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> B_ORC <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> B;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> A_ORC.customerID, A_ORC.name,</span><br><span class="line">A_ORC.age, A_ORC.address <span class="keyword">join</span></span><br><span class="line">B_ORC.role, B_ORC.department, B_ORC.salary</span><br><span class="line"><span class="keyword">ON</span> A_ORC.customerID=B_ORC.customerID;</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;<strong>F、压缩格式</strong></p>
<p>&emsp;&emsp;大数据场景下存储格式压缩格式尤为关键，可以提升计算速度，减少存储空间，降低网络io，磁盘io，所以要选择合适的压缩格式和存储格式，参考<a href="https://blog.csdn.net/yu0_zhang0/article/details/79524842" target="_blank" rel="noopener">Hadoop中的压缩与解压详解</a>    </p>
<p>&emsp;&emsp;<strong>G、MAP JOIN</strong></p>
<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g50n64yge1j312u0rywhh.jpg" alt="mapjoin"></p>
<p>&emsp;&emsp;mapjoin简单说就是在Map阶段将小表读入内存，顺序扫描大表完成Join。上图是Hive MapJoin的原理图，出自Facebook工程师Liyin Tang的一篇介绍Join优化的slice，从图中可以看出MapJoin分为两个阶段：</p>
<p>&emsp;&emsp;<strong>1）</strong>通过MapReduce Local Task，将小表读入内存，生成HashTableFiles上传至Distributed Cache中，这里会对HashTableFiles进行压缩。</p>
<p>&emsp;&emsp;<strong>2）</strong>MapReduce Job在Map阶段，每个Mapper从Distributed Cache读取HashTableFiles到内存中，顺序扫描大表，在Map阶段直接进行Join，将数据传递给下一个MapReduce任务。<br>也就是在map端进行join避免了shuffle。</p>
<p>&emsp;&emsp;<strong>H、引擎的选择</strong></p>
<p>&emsp;&emsp;Hive可以使用ApacheTez执行引擎而不是古老的Map-Reduce引擎。 </p>
<p>&emsp;&emsp;我不会详细讨论在这里提到的使用Tez的许多好处; 相反，我想提出一个简单的建议：</p>
<p>&emsp;&emsp;如果它没有在您的环境中默认打开，请在您的Hive查询的开头将以下内容设置为’true’来使用Tez：</p>
<p>&emsp;&emsp;设置<code>hive.execution.engine = tez;</code></p>
<p>&emsp;&emsp;通过上述设置，您执行的每个HIVE查询都将利用Tez。</p>
<p>&emsp;&emsp;<strong>I、Use Vectorization</strong></p>
<p>&emsp;&emsp;向量化查询执行通过一次性批量执行1024行而不是每次单行执行，从而提高扫描，聚合，筛选器和连接等操作的性能。</p>
<p>&emsp;&emsp;在Hive 0.13中引入，此功能显着提高了查询执行时间，并可通过两个参数设置轻松启用：</p>
<p>&emsp;&emsp;设置<code>hive.vectorized.execution.enabled = true;</code></p>
<p>&emsp;&emsp;设置<code>hive.vectorized.execution.reduce.enabled = true;</code></p>
<p>&emsp;&emsp;<strong>J、cost based query optimization</strong></p>
<p>&emsp;&emsp;Hive 自0.14.0开始，加入了一项”Cost based Optimizer”来对HQL执行计划进行优化，这个功能通  过”hive.cbo.enable”来开启。在Hive 1.1.0之后，这个feature是默认开启的,它可以自动优化HQL中多个JOIN的顺序，并选择合适的JOIN算法。</p>
<p>&emsp;&emsp;Hive在提交最终执行前,优化每个查询的执行逻辑和物理执行计划。这些优化工作是交给底层来完成。</p>
<p>&emsp;&emsp;根据查询成本执行进一步的优化，从而产生潜在的不同决策：如何排序连接，执行哪种类型的连接，并行度等等。</p>
<p>&emsp;&emsp;要使用基于成本的优化（也称为CBO），请在查询开始处设置以下参数：</p>
<p>&emsp;&emsp;设置<code>hive.cbo.enable = true;</code></p>
<p>&emsp;&emsp;设置<code>hive.compute.query.using.stats = true;</code></p>
<p>&emsp;&emsp;设置<code>hive.stats.fetch.column.stats = true;</code></p>
<p>&emsp;&emsp;设置<code>hive.stats.fetch.partition.stats = true;</code></p>
<p>&emsp;&emsp;<strong>K、模式选择</strong></p>
<p>&emsp;&emsp;<strong>1）本地模式</strong></p>
<p>&emsp;&emsp;对于大多数情况，Hive可以通过本地模式在单台机器上处理所有任务。</p>
<p>&emsp;&emsp;对于小数据，执行时间可以明显被缩短。通过<code>set hive.exec.mode.local.auto=true</code>（默认为false）设置本地模式。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; set hive.exec.mode.local.auto;</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;<strong>2）并行模式</strong></p>
<p>&emsp;&emsp;Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。</p>
<p>&emsp;&emsp;默认情况下，Hive一次只会执行一个阶段，由于job包含多个阶段，而这些阶段并非完全互相依赖，即：这些阶段可以并行执行，可以缩短整个job的执行时间。设置参数：对于小数据，执行时间可以明显被缩短。通过<code>set hive.exec.parallel=true</code>,或者通过配置文件来完成。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; set hive.exec.parallel;</span><br><span class="line"></span><br><span class="line">hive.exec.parallel=false</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;<strong>3）严格模式</strong></p>
<p>&emsp;&emsp;Hive提供一个严格模式，可以防止用户执行那些可能产生意想不到的影响查询：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">通过设置Hive.mapred.modestrict来完成</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span> Hive.mapred.modestrict;</span><br><span class="line"></span><br><span class="line">Hive.mapred.modestrict is undefined</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;<strong>L、JVM重用</strong></p>
<p>&emsp;&emsp;Hadoop通常是使用派生JVM来执行map和reduce任务的。这时JVM的启动过程可能会造成相当大的开销，尤其是执行的job包含偶成百上千的task任务的情况。JVM重用可以使得JVM示例在同一个job中时候使用N此。通过参数<code>mapred.job.reuse.jvm.num.tasks</code>来设置。</p>
<p>&emsp;&emsp;<strong>M、推测执行</strong></p>
<p>&emsp;&emsp;Hadoop推测执行可以触发执行一些重复的任务，尽管因对重复的数据进行计算而导致消耗更多的计算资源，<br>不过这个功能的目标是通过加快获取单个task的结果以侦测执行慢的TaskTracker加入到没名单的方式来提高整体的任务执行效率。</p>
<p>&emsp;&emsp;Hadoop的推测执行功能由2个配置控制着，通过mapred-site.xml中配置</p>
<p>&emsp;&emsp;<code>mapred.map.tasks.speculative.execution=true</code></p>
<p>&emsp;&emsp;<code>mapred.reduce.tasks.speculative.execution=true</code></p>

      
    </div>
    
    
    

    <div>
    
        
    
    </div>

    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>

      
    </div>


    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>大 吉 大 利！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechat.jpg" alt="想当校长的老王 微信支付">
        <p>微信支付</p>
      </div>
    

    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    想当校长的老王
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://yoursite.com/2019/07/15/Hive学习之路（二）Hive总结及优化/" title="Hive学习之路（二）Hive总结及优化">http://yoursite.com/2019/07/15/Hive学习之路（二）Hive总结及优化/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/优化/" rel="tag"><i class="fa fa-tag"></i> 优化</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/07/12/标签上线/" rel="next" title="标签上线">
                <i class="fa fa-chevron-left"></i> 标签上线
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/07/25/Spark学习之路（一）Spark初识/" rel="prev" title="Spark学习之路（一）Spark初识">
                Spark学习之路（一）Spark初识 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="想当校长的老王">
            
              <p class="site-author-name" itemprop="name">想当校长的老王</p>
              <p class="site-description motion-element" itemprop="description">愿能阅尽天下事，洗手仍能做羹汤</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/Co-Hwang" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://mail.163.com/" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#一、产生背景"><span class="nav-number">1.</span> <span class="nav-text">一、产生背景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、Hive深入剖析"><span class="nav-number">2.</span> <span class="nav-text">二、Hive深入剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1、Hive的特征："><span class="nav-number">2.1.</span> <span class="nav-text">1、Hive的特征：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2、Hive基本语法"><span class="nav-number">2.2.</span> <span class="nav-text">2、Hive基本语法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3、Hive与关系型数据库的区别"><span class="nav-number">2.3.</span> <span class="nav-text">3、Hive与关系型数据库的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4、Hive的优点"><span class="nav-number">2.4.</span> <span class="nav-text">4、Hive的优点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5、SQL转化为MapReduce的过程"><span class="nav-number">2.5.</span> <span class="nav-text">5、SQL转化为MapReduce的过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6、Hive内部表和外部表的区别"><span class="nav-number">2.6.</span> <span class="nav-text">6、Hive内部表和外部表的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7、行式存储vs列式存储"><span class="nav-number">2.7.</span> <span class="nav-text">7、行式存储vs列式存储</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8、Hive哪些查询会执行MR"><span class="nav-number">2.8.</span> <span class="nav-text">8、Hive哪些查询会执行MR</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9、Hive静态分区、动态分区"><span class="nav-number">2.9.</span> <span class="nav-text">9、Hive静态分区、动态分区</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10、删除分区"><span class="nav-number">2.10.</span> <span class="nav-text">10、删除分区</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11、Hive优化"><span class="nav-number">2.11.</span> <span class="nav-text">11、Hive优化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12、Hive优化之小文件问题及其解决方案"><span class="nav-number">2.12.</span> <span class="nav-text">12、Hive优化之小文件问题及其解决方案</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#小文件是如何产生的"><span class="nav-number">2.12.1.</span> <span class="nav-text">小文件是如何产生的</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#小文件问题的影响"><span class="nav-number">2.12.2.</span> <span class="nav-text">小文件问题的影响</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#小文件问题的解决方案"><span class="nav-number">2.12.3.</span> <span class="nav-text">小文件问题的解决方案</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">这個人好蠢、</span>

  
</div>

<!--
  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>
-->



        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访客数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 浏览量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  





  
  







  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
